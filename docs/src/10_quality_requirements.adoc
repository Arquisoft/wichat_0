ifndef::imagesdir[:imagesdir: ../images]

[[section-quality-scenarios]]
== Quality Requirements

=== Quality Tree

[plantuml, quality-tree, png]
left to right direction
skinparam nodesep 10
skinparam ranksep 50

rectangle "Quality" as root {
  rectangle "1. Functional Suitability" as q1
  rectangle "2. Reliability" as q2
  rectangle "3. Performance Efficiency" as q3
  rectangle "Secondary Qualities" as secondary {
    rectangle "4. Maintainability" as q4
    rectangle "5. Usability" as q5
    rectangle "6. Portability" as q6
    rectangle "7. Security" as q7
  }
}

q1 --> q2
q1 --> q3
root --> secondary

=== Quality Scenarios

[cols="1,3,2", options="header"]
|===
| ID | Scenario | Test Criteria

| FS-1
| Stimulus: User requests a hint during a quiz question
|Response: System provides a relevant hint from the LLM within 3 seconds
|Measurement: 95% of hints are factually correct and derived from Wikidata

| FS-2
| Stimulus: User registers and logs into the system
|Response: User data is saved and accessible across sessions
|Measurement: MongoDB confirms 100% successful user data persistence

| REL-1
| Stimulus: System generates a quiz question from Wikidata
|Response: Question includes one correct answer and three plausible distractors
|Measurement: SPARQL query validation ensures answer accuracy

| REL-2
| Stimulus: LLM processes a hint request
|Response: No hallucinations or incorrect information in 90% of responses
|Measurement: Manual validation of 50 random hints against Wikidata facts

| PE-1
| Stimulus: 100 concurrent users play the quiz simultaneously
|Response: Average API response time remains under 1.5 seconds
|Measurement: Load testing with Locust.io simulating peak traffic

| PE-2
| Stimulus: System queries Wikidata for question generation
|Response: Question generation completes in under 2 seconds
|Measurement: Cached queries and response time metrics

| MNT-1
| Stimulus: A new question category is added to the system
|Response: Implementation is completed within 2 hours by any team member
|Measurement: Modular code structure with clear documentation

| USAB-1
| Stimulus: A first-time user starts the game
|Response: User successfully completes a quiz within 5 minutes
|Measurement: User testing with 5 novice participants

| SEC-1
| Stimulus: Brute-force login attempt detected
|Response: Account is locked after 5 failed attempts
|Measurement: Penetration testing with OWASP ZAP confirms security
|===

==== Key Constraints & Rationale

    Academic Focus: Prioritized scenarios that align with course objectives, such as API integration, modularity, and testing.

    Resource Limits: Assumes free-tier cloud hosting (e.g., Heroku Student) and limited LLM API quotas.

    Team Skills: Chose React, Node.js, and MongoDB for alignment with the teamâ€™s curriculum and skill set.

    Timebox: Scenarios are achievable within a 12-week academic timeline with 5 developers.

==== Trade-off Decisions
[cols="1,3,1"]
|===
| Factor | Decision | Impact
| LLM Accuracy vs Cost | Use Empathy API for basic hints | May require manual validation to ensure accuracy
| Fresh Data vs Performance | Cache Wikidata queries for 1 hour | Accept stale data during gameplay to improve performance
| Security vs Complexity | Implement JWT authentication without OAuth | Reduced implementation time but lower security
|===
